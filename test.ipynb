{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7caa6ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "from rich.console import Console\n",
    "from printer import Printer\n",
    "from agents import Runner, custom_span, gen_trace_id, trace\n",
    "\n",
    "#! brew install graphicsmagick\n",
    "#! pip install py-zerox\n",
    "#! brew install poppler\n",
    "from pyzerox import zerox\n",
    "import docx\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0615888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add current path to sys.path\n",
    "sys.path.append(os.getcwd())\n",
    "from printer import Printer\n",
    "\n",
    "from helper_agents.resume_parser_agent import resume_parser_agent, ResumeItem\n",
    "from helper_agents.jd_parser_agent import jd_parser_agent, web_scraper_tool, JDItem\n",
    "from helper_agents.content_revise_agent import content_revise_agent\n",
    "from helper_agents.expression_revise_agent import expression_revise_agent\n",
    "from helper_agents.evaluation_agent import evaluation_agent, EvaluationResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258f0cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResumeImprovementManager:\n",
    "    def __init__(self):\n",
    "        self.console = Console()\n",
    "        self.printer = Printer(self.console)\n",
    "\n",
    "    async def run(\n",
    "        self, target_resume_file_path, jd_website, reference_resume_file_path: str\n",
    "    ) -> None:\n",
    "        # Generate a unique trace ID for this session\n",
    "        trace_id = gen_trace_id()\n",
    "        with trace(\"Resume Improvement trace\", trace_id=trace_id):\n",
    "            self.printer.update_item(\n",
    "                \"trace_id\",\n",
    "                f\"View trace: https://platform.openai.com/traces/trace?trace_id={trace_id}\",\n",
    "                is_done=True,\n",
    "                hide_checkmark=True,\n",
    "            )\n",
    "\n",
    "            self.printer.update_item(\n",
    "                \"starting\",\n",
    "                \"Starting research...\",\n",
    "                is_done=True,\n",
    "                hide_checkmark=True,\n",
    "            )\n",
    "            # Read JD, and parse it\n",
    "            jd_components = await self._get_jd_components(jd_website)\n",
    "            # If jd_components is empty, handle it\n",
    "            if not jd_components:\n",
    "                self.printer.update_item(\"getting_jd\", \"No job description found.\")\n",
    "                return None\n",
    "            elif jd_components.citizenship_requirements:\n",
    "                self.printer.update_item(\"getting_jd\", \"Require citizenship.\")\n",
    "                return None\n",
    "            # Get target resume and reference resume\n",
    "            target_resume_component, reference_resume_component = (\n",
    "                await self._convert_resume_files(\n",
    "                    target_resume_file_path, reference_resume_file_path\n",
    "                )\n",
    "            )\n",
    "\n",
    "            score = await self._evaluate_resume(\n",
    "                target_resume_component, reference_resume_component, jd_components\n",
    "            )\n",
    "\n",
    "            revised_resume = target_resume_component\n",
    "\n",
    "            # At most 3 iterations\n",
    "            for i in range(3):\n",
    "                if score.content_score < 8:\n",
    "                    revised_resume = await self._revise_resume_content(\n",
    "                        revised_resume, jd_components\n",
    "                    )\n",
    "                if score.expression_score < 8:\n",
    "                    revised_resume = await self._revise_resume_expression(\n",
    "                        revised_resume, reference_resume_component\n",
    "                    )\n",
    "\n",
    "            final_report = f\"Final Revised Resume\\n\\n{revised_resume}\"\n",
    "            self.printer.update_item(\"final_report\", final_report, is_done=True)\n",
    "\n",
    "            self.printer.end()\n",
    "\n",
    "        print(\"\\n\\n=====REPORT=====\\n\\n\")\n",
    "        print(f\"Report: {revised_resume.markdown_report}\")\n",
    "\n",
    "    async def file_to_markdown(self, file_path, output_path):\n",
    "        \"\"\"Convert files to markdown. Local filepath and file URL supported\"\"\"\n",
    "        # Ensure parent directory exists\n",
    "\n",
    "        # If output file already exists, you may choose to overwrite or skip\n",
    "        if os.path.isfile(output_path):\n",
    "            return \"The output file already exists. No conversion\"\n",
    "        if file_path.endswith(\".md\"):\n",
    "            with open(file_path, \"r\") as f, open(output_path, \"w\") as out_f:\n",
    "                out_f.write(f.read())\n",
    "                return \"Conversion done\"\n",
    "        if file_path.endswith(\".docx\"):\n",
    "            doc = docx.Document(file_path)\n",
    "            txt = \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "            # save the txt to a md file\n",
    "            with open(output_path, \"w\") as f:\n",
    "                f.write(txt)\n",
    "            return \"Conversion done\"\n",
    "\n",
    "        model = \"gpt-4o-mini\"\n",
    "        custom_system_prompt = \"\"\"\n",
    "            You are a resume parser. Extract the text from the PDF, \n",
    "            preserving headings, bullet points, and tables. \n",
    "            Return the output in Markdown format.\n",
    "        \"\"\"\n",
    "        kwargs = {}\n",
    "        # select_pages = None\n",
    "        await zerox(\n",
    "            file_path=file_path,\n",
    "            model=model,\n",
    "            output_dir=output_path,\n",
    "            custom_system_prompt=custom_system_prompt,\n",
    "            **kwargs,\n",
    "        )\n",
    "        return \"Conversion done\"\n",
    "\n",
    "    async def _convert_resume_files(\n",
    "        self, target_resume_file_path, reference_resume_file_path\n",
    "    ):\n",
    "        self.printer.update_item(\"converting\", \"Converting resume files...\")\n",
    "        # Convert both resume to markdown file if they are not\n",
    "        converted_resume_target_path = \"./converted_resume/target_resume.md\"\n",
    "        converted_resume_reference_path = \"./converted_resume/reference_resume.md\"\n",
    "        outputmessage1 = await self.file_to_markdown(\n",
    "            target_resume_file_path, converted_resume_target_path\n",
    "        )\n",
    "        self.printer.update_item(\"converting\", outputmessage1)\n",
    "        outputmessage2 = await self.file_to_markdown(\n",
    "            reference_resume_file_path, converted_resume_reference_path\n",
    "        )\n",
    "        self.printer.update_item(\"converting\", outputmessage2)\n",
    "\n",
    "        with open(converted_resume_target_path, \"r\") as file:\n",
    "            target_resume_content = file.read()\n",
    "        with open(converted_resume_reference_path, \"r\") as file:\n",
    "            reference_resume_content = file.read()\n",
    "\n",
    "        # Get target resume components\n",
    "        target_resume_components = await Runner.run(\n",
    "            starting_agent=resume_parser_agent,\n",
    "            input=f\"Resume content: {target_resume_content}\",\n",
    "        )\n",
    "        # Get reference resume components\n",
    "        reference_resume_components = await Runner.run(\n",
    "            starting_agent=resume_parser_agent,\n",
    "            input=f\"Resume content: {reference_resume_content}\",\n",
    "        )\n",
    "        self.printer.mark_item_done(\"converting\")\n",
    "\n",
    "        # Return both resume components\n",
    "        return target_resume_components.final_output_as(\n",
    "            ResumeItem\n",
    "        ), reference_resume_components.final_output_as(ResumeItem)\n",
    "\n",
    "    async def _get_jd_components(self, jd_website: str) -> JDItem:\n",
    "        self.printer.update_item(\"getting_jd\", \"Analyzing job description...\")\n",
    "        try:\n",
    "            job_description = web_scraper_tool(jd_website)\n",
    "        except Exception as e:\n",
    "            self.printer.update_item(\"getting_jd\", f\"Error: {e}\")\n",
    "            # End the agent\n",
    "            return None\n",
    "\n",
    "        jd_components = await Runner.run(\n",
    "            starting_agent=jd_parser_agent,\n",
    "            input=f\"Job description: {job_description}\",\n",
    "        )\n",
    "        self.printer.mark_item_done(\"getting_jd\")\n",
    "        return jd_components.final_output_as(JDItem)\n",
    "\n",
    "    async def _revise_resume_content(\n",
    "        self,\n",
    "        target_resume_components: ResumeItem,\n",
    "        reference_resume_components: ResumeItem,\n",
    "        jd_components: JDItem,\n",
    "    ) -> ResumeItem:\n",
    "        self.printer.update_item(\"revising_resume\", \"Revising resume content...\")\n",
    "        try:\n",
    "            revised_resume = await Runner.run(\n",
    "                starting_agent=content_revise_agent,\n",
    "                input=json.dumps(\n",
    "                    {\n",
    "                        \"target_resume_components\": target_resume_components,\n",
    "                        \"jd_components\": jd_components,\n",
    "                    }\n",
    "                ),\n",
    "            )\n",
    "            self.printer.mark_item_done(\"revising_resume\")\n",
    "            return revised_resume.final_output_as(ResumeItem)\n",
    "        except Exception as e:\n",
    "            self.printer.update_item(\"revising_resume\", f\"Error: {e}\")\n",
    "            return None\n",
    "\n",
    "    async def _evaluate_resume(\n",
    "        self,\n",
    "        target_resume_components: ResumeItem,\n",
    "        reference_resume_components: ResumeItem,\n",
    "        jd_components: JDItem,\n",
    "    ) -> EvaluationResult:\n",
    "        self.printer.update_item(\"evaluating\", \"Evaluating resume...\")\n",
    "        result = await Runner.run(\n",
    "            starting_agent=evaluation_agent,\n",
    "            input=json.dumps(\n",
    "                {\n",
    "                    \"target_resume_components\": target_resume_components.dict(),\n",
    "                    \"reference_resume_components\": reference_resume_components.dict(),\n",
    "                    \"job_description\": jd_components.dict(),\n",
    "                }\n",
    "            ),\n",
    "        )\n",
    "        self.printer.mark_item_done(\"evaluating\")\n",
    "        return result.final_output_as(EvaluationResult)\n",
    "\n",
    "    async def _revise_resume_expression(\n",
    "        self,\n",
    "        target_resume_components: ResumeItem,\n",
    "        reference_resume_components: ResumeItem,\n",
    "    ) -> ResumeItem:\n",
    "        self.printer.update_item(\n",
    "            \"revising_expression\", \"Revising resume's expression...\"\n",
    "        )\n",
    "        try:\n",
    "            revised_resume = await Runner.run(\n",
    "                starting_agent=content_revise_agent,\n",
    "                input=json.dumps(\n",
    "                    {\n",
    "                        \"target_resume_components\": target_resume_components,\n",
    "                        \"reference_resume_components\": reference_resume_components,\n",
    "                    }\n",
    "                ),\n",
    "            )\n",
    "            self.printer.mark_item_done(\"revising_expression\")\n",
    "            return revised_resume.final_output_as(ResumeItem)\n",
    "        except Exception as e:\n",
    "            self.printer.update_item(\"revising_expression\", f\"Error: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69288b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# from manager import ResearchManager\n",
    "\n",
    "\n",
    "await ResumeImprovementManager().run(\n",
    "    \"./target_resume.docx\",\n",
    "    \"https://jobright.ai/jobs/info/68ace77ed627244576e49be6\",\n",
    "    \"./converted_reference_resume/reference_resume.md\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c871d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = ResumeImprovementManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30c745d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_components = await example._get_jd_components(\n",
    "    \"https://jobright.ai/jobs/info/68ace77ed627244576e49be6\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7e5ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_resume_component, reference_resume_component = (\n",
    "    await example._convert_resume_files(\n",
    "        \"./target_resume.docx\", \"./converted_resume/reference_resume.md\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf4fd34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResumeItem(summary='B-round startup veteran tech lead with eight years of cloud development experience across verticals, including healthcare, ML infra, and Edge AI agents. Skilled in multi-agent orchestration and extensive computing systems.', hard_skills=['C++', 'C#', 'Java', 'Python', 'SQL', 'Large Scale Distributed Systems', 'LLM Orchestration'], projects=[Project(title='Senior Software Development Engineer - Elastic Infra Platform', company='GLOBAL CLOUD INC.', project_name='Union Deployment', description=['Architected batch compute systems for next-gen SDP, helping CrowdStrike avoid another historic outage.', 'Achieved 99.99% update coverage for hybrid clouds serving RedRock, ClosedAI, Walmart, and BinaryDance.', 'Spearheaded cross-team efforts building data warehouses, ensuring global rollout visibility for leadership.', \"Pioneered enhancing small LLMs' reasoning via RL self-play and MCTS to build an infra-rollout agent.\"], location='Seattle, WA'), Project(title='Software Development Engineer II - Core Infra Platform', company='GLOBAL CLOUD INC.', project_name='Northstar', description=['Identified 49 new metrics for rollout failure analysis, saving over $2M in losses for Walmart and RedRock.', 'Simplified waterfall of data aggregation for RTB Ad Exchange, saving advertisers 5% ad revenue loss.', 'Improved customer satisfaction by refining latency rollout algorithms, cutting rollout time by 30%.', 'Innovated alert merging, cutting Mean Time to Detect from 24h to 30m, ensuring 99.9% SLA uptime.'], location='Seattle, WA'), Project(title='Software Engineer', company='TECHCORP LLC', project_name='Health Plan Marketplace', description=['Led ML infra migration to AWS, achieving 99.9% availability for benefit recommendation service.', 'Designed a distributed message queue streamlining enterprise integration between BDP and OfficeDay.', 'Implemented a Bloom-Filter caching service for password breach detection, saving over $200k in cloud costs.'], location='San Francisco, CA'), Project(title='Software Engineer', company='HEALTHDATA SYSTEMS', project_name='CareChart', description=['Designed a data placement service for S3-like storage, ensuring 99.9999% data durability for data lakes.', 'Built a garbage collector to reclaim space via compaction, handling deleted, orphaned, and corrupted data.'], location='Chicago, IL')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_resume_component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2be8fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = await example._evaluate_resume(\n",
    "    target_resume_component, reference_resume_component, jd_components\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "613d9619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationResult(content_score=8, expression_score=7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cea9f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "revised_resume = target_resume_component\n",
    "\n",
    "# At most 3 iterations\n",
    "for i in range(3):\n",
    "    if score.content_score < 8:\n",
    "        revised_resume = example._revise_resume_content(\n",
    "            target_resume_component, jd_components\n",
    "        )\n",
    "    if score.expression_score < 8:\n",
    "        revised_resume = example._revise_resume_expression(\n",
    "            target_resume_component, reference_resume_component\n",
    "        )\n",
    "\n",
    "final_report = f\"Final Revised Resume\\n\\n{revised_resume}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f2bdbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Final Revised Resume\\n\\n<coroutine object ResumeImprovementManager._revise_resume_expression at 0x115444b40>'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1dbfad9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type coroutine is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrevised_resume\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py:231\u001b[39m, in \u001b[36mdumps\u001b[39m\u001b[34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    226\u001b[39m \u001b[38;5;66;03m# cached encoder\u001b[39;00m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m skipkeys \u001b[38;5;129;01mand\u001b[39;00m ensure_ascii \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    228\u001b[39m     check_circular \u001b[38;5;129;01mand\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m separators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    230\u001b[39m     default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort_keys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_encoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONEncoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:200\u001b[39m, in \u001b[36mJSONEncoder.encode\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m    202\u001b[39m     chunks = \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:258\u001b[39m, in \u001b[36mJSONEncoder.iterencode\u001b[39m\u001b[34m(self, o, _one_shot)\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    254\u001b[39m     _iterencode = _make_iterencode(\n\u001b[32m    255\u001b[39m         markers, \u001b[38;5;28mself\u001b[39m.default, _encoder, \u001b[38;5;28mself\u001b[39m.indent, floatstr,\n\u001b[32m    256\u001b[39m         \u001b[38;5;28mself\u001b[39m.key_separator, \u001b[38;5;28mself\u001b[39m.item_separator, \u001b[38;5;28mself\u001b[39m.sort_keys,\n\u001b[32m    257\u001b[39m         \u001b[38;5;28mself\u001b[39m.skipkeys, _one_shot)\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:180\u001b[39m, in \u001b[36mJSONEncoder.default\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[32m    162\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m \n\u001b[32m    179\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis not JSON serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type coroutine is not JSON serializable"
     ]
    }
   ],
   "source": [
    "json.dumps(revised_resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627c532b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
